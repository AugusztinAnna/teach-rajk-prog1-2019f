{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import lxml\n",
    "import bs4 as bs\n",
    "import urllib.request"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## lépések \n",
    "#### 1) introduction oldalon megtalálni a személyiségtípus nevét\n",
    "#### 2) ebből a névből létrehozni egy .txt file-t a megfelelő mappában\n",
    "#### 3) az introduction oldal paragraphjait hozzáadni \n",
    "#### 4) átmenni a következő oldalra, itt is a main descriptiont hozzáadni \n",
    "#### 5) így tovább, de az \"academy\" oldal már nem kell\n",
    "#### 6) jöhet a következő típus (types_URLend[i+1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 16 personalities\n",
    "\n",
    "personalities = [\"adventurer\",\"advocate\",\"architect\",\"campaigner\",\"commander\",\"consul\",\"debater\",\\\n",
    "             \"defender\",\"entertainer\",\"entrepreneur\",\"executive\",\"logician\",\"logistician\",\"mediator\",\\\n",
    "             \"protagonist\",\"virtuoso\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "myURL = 'https://www.16personalities.com/personality-types'\n",
    "URL = 'https://www.16personalities.com'\n",
    "sauce = urllib.request.urlopen(myURL).read()\n",
    "soup = bs.BeautifulSoup(sauce,'lxml')\n",
    "body = soup.body\n",
    "nav = soup.nav\n",
    "URLs = []\n",
    "types_URL = []\n",
    "substring1 = \"personality-types\"\n",
    "\n",
    "    \n",
    "for url in nav.find_all('a'):\n",
    "    URLs.append(url.get('href'))\n",
    "\n",
    "for i in range(0,len(URLs)):\n",
    "    if (URLs[i].find(substring1)) == 32:\n",
    "        types_URL.append(URLs[i])\n",
    "\n",
    "for i in range(0,len(types_URL)):\n",
    "    sauce = urllib.request.urlopen(types_URL[i]).read()\n",
    "    soup = bs.BeautifulSoup(sauce,'lxml')\n",
    "    nav = soup.nav\n",
    "\n",
    "types_URLend = []\n",
    "for url in nav.find_all('a'):\n",
    "    if url.get('href')[0] == '/':\n",
    "        types_URLend.append(url.get('href'))\n",
    "\n",
    "\n",
    "for i in range(0,len(types_URLend[i])-1):\n",
    "    myURL = URL + types_URLend[i]\n",
    "    sauce1 = urllib.request.urlopen(myURL).read()\n",
    "    soup1 = bs.BeautifulSoup(sauce1,'lxml')\n",
    "    body1 = soup1.body\n",
    "    \n",
    "    title = body1.find_all('h2')\n",
    "    length = len(title) - 1\n",
    "    name = title[length].text.lower()\n",
    "    pers = name.partition(' ')[0]\n",
    "    \n",
    "    file = pers + '.txt'\n",
    "    f = open(file,\"w+\")\n",
    "    f.close()\n",
    "    \n",
    "    for paragraph in body1.find_all('article', attrs={\"main description\"}):\n",
    "        text1 = paragraph.text + '\\n'\n",
    "        f = open(file,\"a+\")\n",
    "        f.write(text1)\n",
    "        f.close()\n",
    "\n",
    "    for i in range(0,7):\n",
    "        next_link = body1.find(\"div\", attrs={\"class\": \"part right\"}).find(\"type-nav-button\")['href']\n",
    "        sauce2 = urllib.request.urlopen(next_link).read()\n",
    "        soup2 = bs.BeautifulSoup(sauce2,'lxml')\n",
    "        body2 = soup2.body\n",
    "        for paragraph2 in body2.find_all('article', attrs={\"main description\"}):\n",
    "            text2 = paragraph2.text + '\\n'\n",
    "            f = open(file,\"a+\")\n",
    "            f.write(text2)\n",
    "            f.close()\n",
    "        \n",
    "        \n",
    "        next_link = urllib.request.urlopen(next_link).read()\n",
    "        next_link = bs.BeautifulSoup(next_link,'lxml')\n",
    "        next_link = next_link.body\n",
    "\n",
    "        body1 = next_link"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# zodiac signs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "myURLzodiac = 'https://www.horoscope.com/zodiac-signs'\n",
    "saucezod = urllib.request.urlopen(myURLzodiac).read()\n",
    "soupzod = bs.BeautifulSoup(saucezod,'lxml')\n",
    "bodyzod = soupzod.body\n",
    "\n",
    "signs_link = []\n",
    "for url in bodyzod.find_all('a', attrs= {\"class\": \"card\"}):\n",
    "    signs_link.append(url.get('href'))\n",
    "    \n",
    "signs_list = []\n",
    "for i in range(0,len(signs_link)):\n",
    "    myURLnext = signs_link[i]\n",
    "    saucezod2 = urllib.request.urlopen(myURLnext).read()\n",
    "    soupzod2 = bs.BeautifulSoup(saucezod2,'lxml')\n",
    "    bodyzod2 = soupzod2.body\n",
    "    for headliner in bodyzod2.find_all('h2'):\n",
    "        title = headliner.text\n",
    "    b = 0\n",
    "    if title[0] == \" \":\n",
    "        b = 1\n",
    "    elif title[0] == \" \":\n",
    "        b = 0\n",
    "    name = \"\"\n",
    "    for letter in range(b,len(title)):\n",
    "        name += title[letter]\n",
    "    pers = name.partition(' ')[0]\n",
    "    signs_list.append(pers)\n",
    "    filename = pers + '.txt'\n",
    "\n",
    "    for paragraph in bodyzod2.find_all('p'):\n",
    "        textzod = '\\n' + paragraph.text\n",
    "        #f = open(filename,\"a\")\n",
    "        #f.write(textzod)\n",
    "        #f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "#signs_list\n",
    "myURLzodiac_other = 'https://labyrinthos.co/blogs/astrology-horoscope-zodiac-signs/list-of-12-zodiac-signs-dates-meanings-symbols'\n",
    "saucezod3 = urllib.request.urlopen(myURLzodiac_other).read()\n",
    "soupzod3 = bs.BeautifulSoup(saucezod3,'lxml')\n",
    "bodyzod3 = soupzod3.body\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "for headliners in bodyzod3.find_all('h1', attrs = {'itemprop': 'headline'}):\n",
    "    title = headliners.text\n",
    "    name = title.split()[3]\n",
    "\n",
    "signs_links2 = []\n",
    "for i in range(0,len(signs_list)):\n",
    "    title = signs_list[i] + ' zodiac sign meaning'\n",
    "    for url in bodyzod3.find_all('a', attrs ={'title': title}):\n",
    "        signs_links2.append(url.get('href'))\n",
    "signs_links2_set = list(set(signs_links2))\n",
    "\n",
    "for i in range(0,len(signs_links2_set)):\n",
    "    myURLnext2 = signs_links2_set[i]\n",
    "    saucezod4 = urllib.request.urlopen(myURLnext2).read()\n",
    "    soupzod4 = bs.BeautifulSoup(saucezod4,'lxml')\n",
    "    bodyzod4 = soupzod4.body\n",
    "    for headliners in bodyzod4.find_all('h1', attrs = {'itemprop': 'headline'}):\n",
    "        title = headliners.text\n",
    "        name = title.split()[3]\n",
    "        filename = name + '.txt'\n",
    "\n",
    "    for paragraph in bodyzod4.find_all('div', attrs = {\"itemprop\": \"articleBody\"}):\n",
    "        text_zod2 = '\\n' + paragraph.text\n",
    "        #f = open(filename,\"a\")\n",
    "        #f.write(text_zod2)\n",
    "        #f.close()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
